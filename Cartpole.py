# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T4rxH_9WYZKhQwXPBUCtEfX-dx5vJbaZ
"""

import tensorflow as tf
import scipy.io as sio
import matplotlib.pyplot as plt
import numpy as np
import math

data = sio.loadmat('/mnist.mat')
image = data['images']
label = data['label']

#blah blah
#changed data to NewData
test = 1.5
n_training = 1500
n_test = 6000
training_index = np.arange(n_training)
test_index = np.arange(n_training, n_training + n_test)

training = image[training_index]
test = image[test_index]
training_label = label[training_index]
test_label = label[test_index]

n_epoch = 100
n_batch = 1000
n_steps = math.ceil(n_training / n_batch)
input_dim = 784

n_row = 5
n_col = 5
n_image = n_row * n_col

plt.figure(figsize=(n_row,n_col))
for i in range(n_image):
  plt.subplot(n_row, n_col, i+1)
  plt.imshow(np.transpose(np.reshape(image[i],[28,28])))

def main():
  tf.reset_default_graph()
  n_hidden1 = 100
  acc_v = np.zeros(math.ceil(n_epoch/10)+1)
  acc_tv = np.zeros(math.ceil(n_epoch/10)+1)
  idx = 0
  x = tf.placeholder(tf.float32, [None, input_dim])
  We1 = tf.get_variable("We1", shape=[input_dim, n_hidden1], initializer = tf.contrib.layers.xavier_initializer())
  be1 = tf.Variable(tf.zeros([n_hidden1]))
  y1 = tf.matmul(x, We1) + be1
  y1 = tf.nn.relu(y1)

  Wd1 = tf.get_variable("Wd1", shape=[n_hidden1, input_dim], initializer = tf.contrib.layers.xavier_initializer())
  bd1 = tf.Variable(tf.zeros([input_dim]))
  y = tf.matmul(y1, Wd1) + bd1
  y_true = tf.placeholder(tf.float32, [None, input_dim])

  cost = tf.reduce_mean(tf.pow(y_true - y, 2))

  train_step = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)

  sess = tf.InteractiveSession()
  tf.global_variables_initializer().run()

  for epoch in range(n_epoch):
    if epoch % 10 == 0:
      acc_v[idx] = sess.run(cost, feed_dict = {x: training, y_true: training})
      acc_tv[idx] = sess.run(cost, feed_dict = {x:test, y_true: test})
      print('Epoch: ' + str(epoch) + ', Accuracy (training, test): ' + str(acc_v[idx]) + ',' + str(acc_tv[idx]))
      idx += 1

    list_rnd_idx = np.random.permutation(n_training).tolist()

    for step in range(n_steps):
      begin_idx =step * n_batch
      end_idx = begin_idx + n_batch
      if end_idx >= len(list_rnd_idx):
        end_idx = len(list_rnd_idx) - 1

      rnd_idx = list_rnd_idx[begin_idx:end_idx]

      d_batch = training[rnd_idx]
      l_batch = training[rnd_idx]

      sess.run(train_step, feed_dict = {x: d_batch, y_true: l_batch})

      acc_v[idx] = sess.run(cost, feed_dict = {x: training, y_true: training})
      acc_tv[idx] = sess.run(cost, feed_dict = {x: test, y_true: test})
      print('Epoch: ' + str(epoch) + ', Accuracy (training, test): ' + str(acc_v[idx]) + ', ' + str(acc_tv[idx]))
      recon = sess.run(y, feed_dict = {x: test, y_true: test})
      ff = np.arange(25)
      recon = recon[ff]
      sio.savemat('/nonlinear_wide.mat', mdict = {'recon_nw': recon, 'nw': acc_v, 'nwt': acc_tv})

if __name__ == "__main__":
  main()

xv = np.arange(11)

data1 = sio.loadmat('/nonlinear_narrow.mat')
recon_nn = data1['recon_nn']
nn = data1['nn']
nnt = data1['nnt']

data2 = sio.loadmat('/nonlinear_wide.mat')
recon_nw = data2['recon_nw']
nw = data2['nw']
nwt = data2['nwt']

nn = np.reshape(nn, [11])
nnt = np.reshape(nnt, [11])
nw = np.reshape(nw, [11])
nwt = np.reshape(nwt, [11])

plt.plot(xv, nn, 'b')
plt.plot(xv, nnt, 'b--')
plt.plot(xv, nw, 'r')
plt.plot(xv, nwt, 'r--')
plt.legend(['Narrow (training)', 'Narrow (test)', 'Wide (training)', 'Wide (test)'])
plt.show()

plt.figure(figsize = (n_row, n_col))
for i in range(n_image):
  plt.subplot(n_row, n_col, i+1)
  plt.imshow(np.transpose(np.reshape(test[i], [28,28])))

plt.figure(figsize = (n_row, n_col))
for i in range(n_image):
  plt.subplot(n_row, n_col, i+1)
  plt.imshow(np.transpose(np.reshape(recon_ln[i], [28,28])))

plt.figure(figsize = (n_row, n_col))
for i in range(n_image):
  plt.subplot(n_row, n_col, i+1)
  plt.imshow(np.transpose(np.reshape(recon_lw[i], [28,28])))
